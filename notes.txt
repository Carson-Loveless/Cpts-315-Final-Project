# TEXT NOTES
# Some suggestions:
# 0. Explore different feature sets
# 1. Visualize the features using t-SNE plots to understand which features are more useful.
# 2. Perform feature selection to identify which features are important
# 3. Perform analysis by varying the amount of training data to measure accuracy
# 4. You can also consider exploring interpretability tools
# https://interpret.ml/

For text processing:
https://www.nltk.org/
https://www.nltk.org/howto/sentiment.html
https://www.nltk.org/howto/tokenize.html


Multinomial Naive Bayes training:
https://www.mygreatlearning.com/blog/multinomial-naive-bayes-explained/
https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html
https://buildmedia.readthedocs.org/media/pdf/nltk/latest/nltk.pdf
https://www.datacamp.com/tutorial/naive-bayes-scikit-learn
https://practicaldatascience.co.uk/machine-learning/how-to-create-a-naive-bayes-text-classification-model-using-scikit-learn

SciPy:
https://docs.scipy.org/doc/scipy/reference/sparse.html

install these dependancies:
numPy
scikit learn
nltk
pandas

Possibly:
vader - analyzes words and assigns a sentiment rating negative to positive

Sources:
https://www.mygreatlearning.com/blog/multinomial-naive-bayes-explained/
https://buildmedia.readthedocs.org/media/pdf/nltk/latest/nltk.pdf
https://stackoverflow.com/questions/12291492/lowercase-stop-words-in-nltk-and-storing-the-stop-words-in-the-list
https://pythonspot.com/nltk-stop-words/
https://thatascience.com/learn-machine-learning/bag-of-words/
https://buildmedia.readthedocs.org/media/pdf/nltk/latest/nltk.pdf
https://monkeylearn.com/blog/classification-algorithms/
